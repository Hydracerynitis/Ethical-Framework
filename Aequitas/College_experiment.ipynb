{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import experiment_util as util\n",
    "import models\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import plot_util as putil\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_school</th>\n",
       "      <th>school_accreditation</th>\n",
       "      <th>gender</th>\n",
       "      <th>interest</th>\n",
       "      <th>residence</th>\n",
       "      <th>parent_age</th>\n",
       "      <th>parent_salary</th>\n",
       "      <th>house_area</th>\n",
       "      <th>average_grades</th>\n",
       "      <th>parent_was_in_college</th>\n",
       "      <th>will_go_to_college</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Academic</td>\n",
       "      <td>A</td>\n",
       "      <td>Male</td>\n",
       "      <td>Less Interested</td>\n",
       "      <td>Urban</td>\n",
       "      <td>56</td>\n",
       "      <td>6950000</td>\n",
       "      <td>83.0</td>\n",
       "      <td>84.09</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Academic</td>\n",
       "      <td>A</td>\n",
       "      <td>Male</td>\n",
       "      <td>Less Interested</td>\n",
       "      <td>Urban</td>\n",
       "      <td>57</td>\n",
       "      <td>4410000</td>\n",
       "      <td>76.8</td>\n",
       "      <td>86.91</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Academic</td>\n",
       "      <td>B</td>\n",
       "      <td>Female</td>\n",
       "      <td>Very Interested</td>\n",
       "      <td>Urban</td>\n",
       "      <td>50</td>\n",
       "      <td>6500000</td>\n",
       "      <td>80.6</td>\n",
       "      <td>87.43</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vocational</td>\n",
       "      <td>B</td>\n",
       "      <td>Male</td>\n",
       "      <td>Very Interested</td>\n",
       "      <td>Rural</td>\n",
       "      <td>49</td>\n",
       "      <td>6600000</td>\n",
       "      <td>78.2</td>\n",
       "      <td>82.12</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Academic</td>\n",
       "      <td>A</td>\n",
       "      <td>Female</td>\n",
       "      <td>Very Interested</td>\n",
       "      <td>Urban</td>\n",
       "      <td>57</td>\n",
       "      <td>5250000</td>\n",
       "      <td>75.1</td>\n",
       "      <td>86.79</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Vocational</td>\n",
       "      <td>A</td>\n",
       "      <td>Female</td>\n",
       "      <td>Very Interested</td>\n",
       "      <td>Rural</td>\n",
       "      <td>49</td>\n",
       "      <td>7420000</td>\n",
       "      <td>63.6</td>\n",
       "      <td>85.99</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Academic</td>\n",
       "      <td>B</td>\n",
       "      <td>Female</td>\n",
       "      <td>Less Interested</td>\n",
       "      <td>Rural</td>\n",
       "      <td>51</td>\n",
       "      <td>7480000</td>\n",
       "      <td>84.3</td>\n",
       "      <td>89.72</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Vocational</td>\n",
       "      <td>A</td>\n",
       "      <td>Male</td>\n",
       "      <td>Less Interested</td>\n",
       "      <td>Urban</td>\n",
       "      <td>49</td>\n",
       "      <td>5550000</td>\n",
       "      <td>75.2</td>\n",
       "      <td>79.56</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Academic</td>\n",
       "      <td>B</td>\n",
       "      <td>Male</td>\n",
       "      <td>Uncertain</td>\n",
       "      <td>Rural</td>\n",
       "      <td>53</td>\n",
       "      <td>5840000</td>\n",
       "      <td>105.8</td>\n",
       "      <td>87.18</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Academic</td>\n",
       "      <td>B</td>\n",
       "      <td>Male</td>\n",
       "      <td>Interested</td>\n",
       "      <td>Urban</td>\n",
       "      <td>50</td>\n",
       "      <td>2940000</td>\n",
       "      <td>69.1</td>\n",
       "      <td>86.13</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    type_school school_accreditation  gender         interest residence  \\\n",
       "0      Academic                    A    Male  Less Interested     Urban   \n",
       "1      Academic                    A    Male  Less Interested     Urban   \n",
       "2      Academic                    B  Female  Very Interested     Urban   \n",
       "3    Vocational                    B    Male  Very Interested     Rural   \n",
       "4      Academic                    A  Female  Very Interested     Urban   \n",
       "..          ...                  ...     ...              ...       ...   \n",
       "995  Vocational                    A  Female  Very Interested     Rural   \n",
       "996    Academic                    B  Female  Less Interested     Rural   \n",
       "997  Vocational                    A    Male  Less Interested     Urban   \n",
       "998    Academic                    B    Male        Uncertain     Rural   \n",
       "999    Academic                    B    Male       Interested     Urban   \n",
       "\n",
       "     parent_age  parent_salary  house_area  average_grades  \\\n",
       "0            56        6950000        83.0           84.09   \n",
       "1            57        4410000        76.8           86.91   \n",
       "2            50        6500000        80.6           87.43   \n",
       "3            49        6600000        78.2           82.12   \n",
       "4            57        5250000        75.1           86.79   \n",
       "..          ...            ...         ...             ...   \n",
       "995          49        7420000        63.6           85.99   \n",
       "996          51        7480000        84.3           89.72   \n",
       "997          49        5550000        75.2           79.56   \n",
       "998          53        5840000       105.8           87.18   \n",
       "999          50        2940000        69.1           86.13   \n",
       "\n",
       "     parent_was_in_college  will_go_to_college  \n",
       "0                    False                True  \n",
       "1                    False                True  \n",
       "2                    False                True  \n",
       "3                     True                True  \n",
       "4                    False               False  \n",
       "..                     ...                 ...  \n",
       "995                   True                True  \n",
       "996                   True                True  \n",
       "997                  False                True  \n",
       "998                   True                True  \n",
       "999                   True               False  \n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df=pd.read_csv(\"../Datasets/Kaggle/College/data.csv\")\n",
    "\n",
    "df=raw_df.copy()\n",
    "#df = df.loc[~df.index.duplicated(keep='first')]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>College</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>False Omissin Rate Disparity</th>\n",
       "      <th>False Discover Rate Disparity</th>\n",
       "      <th>Predicted Positive Ratio Disparity</th>\n",
       "      <th>Predicted Prevalance Disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accuracy, False Omissin Rate Disparity, False Discover Rate Disparity, Predicted Positive Ratio Disparity, Predicted Prevalance Disparity]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds_index=np.array_split(df.sample(frac=1).index,5)\n",
    "eval=util.evaluation(df,\"gender\",\"will_go_to_college\",\"Male\",folds_index)\n",
    "pre_df=util.preporcess_transform(df)\n",
    "result=pd.DataFrame([],columns=util.column)\n",
    "result.columns.name=\"College\"\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/Documents/Ethical-Framework/Aequitas/experiment_util.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  new_df=pd.concat([dataframe,pd.DataFrame([series.to_list()],index=[series.name],columns=column)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>College</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>False Omissin Rate Disparity</th>\n",
       "      <th>False Discover Rate Disparity</th>\n",
       "      <th>Predicted Positive Ratio Disparity</th>\n",
       "      <th>Predicted Prevalance Disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.984274</td>\n",
       "      <td>0.639754</td>\n",
       "      <td>1.033412</td>\n",
       "      <td>1.08961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "College        Accuracy  False Omissin Rate Disparity  \\\n",
       "Random Forest     0.904                      0.984274   \n",
       "\n",
       "College        False Discover Rate Disparity  \\\n",
       "Random Forest                       0.639754   \n",
       "\n",
       "College        Predicted Positive Ratio Disparity  \\\n",
       "Random Forest                            1.033412   \n",
       "\n",
       "College        Predicted Prevalance Disparity  \n",
       "Random Forest                         1.08961  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=util.append_Series(result,eval.cross_validation(\"Random Forest\",models.RandomForest,pre_df))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>College</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>False Omissin Rate Disparity</th>\n",
       "      <th>False Discover Rate Disparity</th>\n",
       "      <th>Predicted Positive Ratio Disparity</th>\n",
       "      <th>Predicted Prevalance Disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.984274</td>\n",
       "      <td>0.639754</td>\n",
       "      <td>1.033412</td>\n",
       "      <td>1.089610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.892</td>\n",
       "      <td>1.217328</td>\n",
       "      <td>0.758392</td>\n",
       "      <td>1.003850</td>\n",
       "      <td>1.056136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "College         Accuracy  False Omissin Rate Disparity  \\\n",
       "Random Forest      0.904                      0.984274   \n",
       "Gradient Boost     0.892                      1.217328   \n",
       "\n",
       "College         False Discover Rate Disparity  \\\n",
       "Random Forest                        0.639754   \n",
       "Gradient Boost                       0.758392   \n",
       "\n",
       "College         Predicted Positive Ratio Disparity  \\\n",
       "Random Forest                             1.033412   \n",
       "Gradient Boost                            1.003850   \n",
       "\n",
       "College         Predicted Prevalance Disparity  \n",
       "Random Forest                         1.089610  \n",
       "Gradient Boost                        1.056136  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=util.append_Series(result,eval.cross_validation(\"Gradient Boost\",models.GradientBoost,pre_df))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>College</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>False Omissin Rate Disparity</th>\n",
       "      <th>False Discover Rate Disparity</th>\n",
       "      <th>Predicted Positive Ratio Disparity</th>\n",
       "      <th>Predicted Prevalance Disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.984274</td>\n",
       "      <td>0.639754</td>\n",
       "      <td>1.033412</td>\n",
       "      <td>1.089610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.892</td>\n",
       "      <td>1.217328</td>\n",
       "      <td>0.758392</td>\n",
       "      <td>1.003850</td>\n",
       "      <td>1.056136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FairGBM</th>\n",
       "      <td>0.815</td>\n",
       "      <td>1.225763</td>\n",
       "      <td>1.252017</td>\n",
       "      <td>1.055033</td>\n",
       "      <td>1.111747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "College         Accuracy  False Omissin Rate Disparity  \\\n",
       "Random Forest      0.904                      0.984274   \n",
       "Gradient Boost     0.892                      1.217328   \n",
       "FairGBM            0.815                      1.225763   \n",
       "\n",
       "College         False Discover Rate Disparity  \\\n",
       "Random Forest                        0.639754   \n",
       "Gradient Boost                       0.758392   \n",
       "FairGBM                              1.252017   \n",
       "\n",
       "College         Predicted Positive Ratio Disparity  \\\n",
       "Random Forest                             1.033412   \n",
       "Gradient Boost                            1.003850   \n",
       "FairGBM                                   1.055033   \n",
       "\n",
       "College         Predicted Prevalance Disparity  \n",
       "Random Forest                         1.089610  \n",
       "Gradient Boost                        1.056136  \n",
       "FairGBM                               1.111747  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=util.append_Series(result,eval.cross_validation(\"FairGBM\",models.Fairgbm,pre_df))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 2024-02-14 16:33:11 methods.inprocessing.ExponentiatedGradient - Instantiating estimator '<class 'lightgbm.sklearn.LGBMClassifier'>' with parameters: {'boosting_type': 'dart', 'enable_bundle': False, 'n_estimators': 100, 'num_leaves': 10, 'min_child_samples': 50, 'learning_rate': 0.01, 'n_jobs': 1}.\n",
      "[INFO] 2024-02-14 16:33:11 methods.inprocessing.ExponentiatedGradient - Instantiating constraint '<class 'fairlearn.reductions._moments.utility_parity.FalsePositiveRateParity'>' with parameters: {}.\n",
      "[INFO] 2024-02-14 16:33:11 methods.inprocessing.ExponentiatedGradient - Instantiating reduction '<class 'fairlearn.reductions._exponentiated_gradient.exponentiated_gradient.ExponentiatedGradient'>' with parameters: {'eps': 0.05, 'max_iter': 10}.\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[INFO] 2024-02-14 16:33:14 methods.inprocessing.ExponentiatedGradient - Instantiating estimator '<class 'lightgbm.sklearn.LGBMClassifier'>' with parameters: {'boosting_type': 'dart', 'enable_bundle': False, 'n_estimators': 100, 'num_leaves': 10, 'min_child_samples': 50, 'learning_rate': 0.01, 'n_jobs': 1}.\n",
      "[INFO] 2024-02-14 16:33:14 methods.inprocessing.ExponentiatedGradient - Instantiating constraint '<class 'fairlearn.reductions._moments.utility_parity.FalsePositiveRateParity'>' with parameters: {}.\n",
      "[INFO] 2024-02-14 16:33:14 methods.inprocessing.ExponentiatedGradient - Instantiating reduction '<class 'fairlearn.reductions._exponentiated_gradient.exponentiated_gradient.ExponentiatedGradient'>' with parameters: {'eps': 0.05, 'max_iter': 10}.\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 589, number of negative: 211\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500115 -> initscore=0.000460\n",
      "[LightGBM] [Info] Start training from score 0.000460\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 589, number of negative: 211\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502099 -> initscore=0.008395\n",
      "[LightGBM] [Info] Start training from score 0.008395\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000149 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 589, number of negative: 211\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501864 -> initscore=0.007455\n",
      "[LightGBM] [Info] Start training from score 0.007455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 589, number of negative: 211\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500979 -> initscore=0.003915\n",
      "[LightGBM] [Info] Start training from score 0.003915\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 589, number of negative: 211\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500546 -> initscore=0.002185\n",
      "[LightGBM] [Info] Start training from score 0.002185\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 402, number of negative: 398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502500 -> initscore=0.010000\n",
      "[LightGBM] [Info] Start training from score 0.010000\n",
      "[LightGBM] [Info] Number of positive: 589, number of negative: 211\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501864 -> initscore=0.007455\n",
      "[LightGBM] [Info] Start training from score 0.007455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 589, number of negative: 211\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500979 -> initscore=0.003915\n",
      "[LightGBM] [Info] Start training from score 0.003915\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 589, number of negative: 211\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500546 -> initscore=0.002185\n",
      "[LightGBM] [Info] Start training from score 0.002185\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[INFO] 2024-02-14 16:33:15 methods.inprocessing.ExponentiatedGradient - Instantiating estimator '<class 'lightgbm.sklearn.LGBMClassifier'>' with parameters: {'boosting_type': 'dart', 'enable_bundle': False, 'n_estimators': 100, 'num_leaves': 10, 'min_child_samples': 50, 'learning_rate': 0.01, 'n_jobs': 1}.\n",
      "[INFO] 2024-02-14 16:33:15 methods.inprocessing.ExponentiatedGradient - Instantiating constraint '<class 'fairlearn.reductions._moments.utility_parity.FalsePositiveRateParity'>' with parameters: {}.\n",
      "[INFO] 2024-02-14 16:33:15 methods.inprocessing.ExponentiatedGradient - Instantiating reduction '<class 'fairlearn.reductions._exponentiated_gradient.exponentiated_gradient.ExponentiatedGradient'>' with parameters: {'eps': 0.05, 'max_iter': 10}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000127 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000133 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[LightGBM] [Info] Number of positive: 397, number of negative: 403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496250 -> initscore=-0.015000\n",
      "[LightGBM] [Info] Start training from score -0.015000\n",
      "[INFO] 2024-02-14 16:33:17 methods.inprocessing.ExponentiatedGradient - Instantiating estimator '<class 'lightgbm.sklearn.LGBMClassifier'>' with parameters: {'boosting_type': 'dart', 'enable_bundle': False, 'n_estimators': 100, 'num_leaves': 10, 'min_child_samples': 50, 'learning_rate': 0.01, 'n_jobs': 1}.\n",
      "[INFO] 2024-02-14 16:33:17 methods.inprocessing.ExponentiatedGradient - Instantiating constraint '<class 'fairlearn.reductions._moments.utility_parity.FalsePositiveRateParity'>' with parameters: {}.\n",
      "[INFO] 2024-02-14 16:33:17 methods.inprocessing.ExponentiatedGradient - Instantiating reduction '<class 'fairlearn.reductions._exponentiated_gradient.exponentiated_gradient.ExponentiatedGradient'>' with parameters: {'eps': 0.05, 'max_iter': 10}.\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500276 -> initscore=0.001105\n",
      "[LightGBM] [Info] Start training from score 0.001105\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.505244 -> initscore=0.020978\n",
      "[LightGBM] [Info] Start training from score 0.020978\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504760 -> initscore=0.019041\n",
      "[LightGBM] [Info] Start training from score 0.019041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502555 -> initscore=0.010220\n",
      "[LightGBM] [Info] Start training from score 0.010220\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501442 -> initscore=0.005767\n",
      "[LightGBM] [Info] Start training from score 0.005767\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000131 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504760 -> initscore=0.019041\n",
      "[LightGBM] [Info] Start training from score 0.019041\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502555 -> initscore=0.010220\n",
      "[LightGBM] [Info] Start training from score 0.010220\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501442 -> initscore=0.005767\n",
      "[LightGBM] [Info] Start training from score 0.005767\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 405, number of negative: 395\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506250 -> initscore=0.025001\n",
      "[LightGBM] [Info] Start training from score 0.025001\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504742 -> initscore=0.018968\n",
      "[LightGBM] [Info] Start training from score 0.018968\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.502542 -> initscore=0.010167\n",
      "[LightGBM] [Info] Start training from score 0.010167\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 582, number of negative: 218\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 799\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501433 -> initscore=0.005734\n",
      "[LightGBM] [Info] Start training from score 0.005734\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[INFO] 2024-02-14 16:33:18 methods.inprocessing.ExponentiatedGradient - Instantiating estimator '<class 'lightgbm.sklearn.LGBMClassifier'>' with parameters: {'boosting_type': 'dart', 'enable_bundle': False, 'n_estimators': 100, 'num_leaves': 10, 'min_child_samples': 50, 'learning_rate': 0.01, 'n_jobs': 1}.\n",
      "[INFO] 2024-02-14 16:33:18 methods.inprocessing.ExponentiatedGradient - Instantiating constraint '<class 'fairlearn.reductions._moments.utility_parity.FalsePositiveRateParity'>' with parameters: {}.\n",
      "[INFO] 2024-02-14 16:33:18 methods.inprocessing.ExponentiatedGradient - Instantiating reduction '<class 'fairlearn.reductions._exponentiated_gradient.exponentiated_gradient.ExponentiatedGradient'>' with parameters: {'eps': 0.05, 'max_iter': 10}.\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:214: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.pos_basis[i][\"+\", e, g] = 1\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_moments/utility_parity.py:215: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  self.neg_basis[i][\"-\", e, g] = 1\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 590, number of negative: 210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499883 -> initscore=-0.000467\n",
      "[LightGBM] [Info] Start training from score -0.000467\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 590, number of negative: 210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000156 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497886 -> initscore=-0.008454\n",
      "[LightGBM] [Info] Start training from score -0.008454\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 590, number of negative: 210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498154 -> initscore=-0.007384\n",
      "[LightGBM] [Info] Start training from score -0.007384\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 590, number of negative: 210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499041 -> initscore=-0.003838\n",
      "[LightGBM] [Info] Start training from score -0.003838\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 590, number of negative: 210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499467 -> initscore=-0.002132\n",
      "[LightGBM] [Info] Start training from score -0.002132\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 590, number of negative: 210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498136 -> initscore=-0.007455\n",
      "[LightGBM] [Info] Start training from score -0.007455\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 590, number of negative: 210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499029 -> initscore=-0.003886\n",
      "[LightGBM] [Info] Start training from score -0.003886\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 590, number of negative: 210\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499460 -> initscore=-0.002161\n",
      "[LightGBM] [Info] Start training from score -0.002161\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n",
      "[LightGBM] [Info] Number of positive: 398, number of negative: 402\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 796\n",
      "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497500 -> initscore=-0.010000\n",
      "[LightGBM] [Info] Start training from score -0.010000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n",
      "/home/kdai332/.conda/envs/Aequitas-venv/lib/python3.10/site-packages/fairlearn/reductions/_exponentiated_gradient/_lagrangian.py:246: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  h_error = self.obj.gamma(h)[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>College</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>False Omissin Rate Disparity</th>\n",
       "      <th>False Discover Rate Disparity</th>\n",
       "      <th>Predicted Positive Ratio Disparity</th>\n",
       "      <th>Predicted Prevalance Disparity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.984274</td>\n",
       "      <td>0.639754</td>\n",
       "      <td>1.033412</td>\n",
       "      <td>1.089610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boost</th>\n",
       "      <td>0.892</td>\n",
       "      <td>1.217328</td>\n",
       "      <td>0.758392</td>\n",
       "      <td>1.003850</td>\n",
       "      <td>1.056136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FairGBM</th>\n",
       "      <td>0.815</td>\n",
       "      <td>1.225763</td>\n",
       "      <td>1.252017</td>\n",
       "      <td>1.055033</td>\n",
       "      <td>1.111747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FairLearn</th>\n",
       "      <td>0.842</td>\n",
       "      <td>1.281027</td>\n",
       "      <td>0.902060</td>\n",
       "      <td>1.022301</td>\n",
       "      <td>1.082331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "College         Accuracy  False Omissin Rate Disparity  \\\n",
       "Random Forest      0.904                      0.984274   \n",
       "Gradient Boost     0.892                      1.217328   \n",
       "FairGBM            0.815                      1.225763   \n",
       "FairLearn          0.842                      1.281027   \n",
       "\n",
       "College         False Discover Rate Disparity  \\\n",
       "Random Forest                        0.639754   \n",
       "Gradient Boost                       0.758392   \n",
       "FairGBM                              1.252017   \n",
       "FairLearn                            0.902060   \n",
       "\n",
       "College         Predicted Positive Ratio Disparity  \\\n",
       "Random Forest                             1.033412   \n",
       "Gradient Boost                            1.003850   \n",
       "FairGBM                                   1.055033   \n",
       "FairLearn                                 1.022301   \n",
       "\n",
       "College         Predicted Prevalance Disparity  \n",
       "Random Forest                         1.089610  \n",
       "Gradient Boost                        1.056136  \n",
       "FairGBM                               1.111747  \n",
       "FairLearn                             1.082331  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result=util.append_Series(result,eval.cross_validation(\"FairLearn\",models.Fairlearn,pre_df))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/Documents/Ethical-Framework/Aequitas/plot_util.py:11: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ax.text(x[i]-x_range*0.15,y[i]+y_range*0.02,annotations[i])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('_mpl-gallery')\n",
    "\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(2,2,figsize=(10,8))\n",
    "\n",
    "putil.plot_scatter(ax[0][0],result[\"Accuracy\"],result[\"False Omissin Rate Disparity\"],\"Accuracy VS False Omissin Rate Disparity\",result.index)\n",
    "putil.plot_scatter(ax[0][1],result[\"Accuracy\"],result[\"False Discover Rate Disparity\"],\"Accuracy VS False Discover Rate Disparity\",result.index)\n",
    "putil.plot_scatter(ax[1][0],result[\"Accuracy\"],result[\"Predicted Positive Ratio Disparity\"],\"Accuracy VS Predicted Positive Ratio Disparity\",result.index)\n",
    "putil.plot_scatter(ax[1][1],result[\"Accuracy\"],result[\"Predicted Prevalance Disparity\"],\"Accuracy VS Predicted Prevalance Disparity\",result.index)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
