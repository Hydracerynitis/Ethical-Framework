{
  "title": "BBQ (Bias Benchmark for Question Answering)",
  "header": [
    {
      "value": "Model/adapter",
      "markdown": false,
      "metadata": {}
    },
    {
      "value": "EM",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\nQuasi-exact match: Fraction of instances that the predicted output matches a correct reference up to light processing.",
      "markdown": false,
      "lower_is_better": false,
      "metadata": {
        "metric": "EM",
        "run_group": "BBQ"
      }
    },
    {
      "value": "BBQ (ambiguous)",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\nBBQ (ambiguous): Metric of [Parrish et al. (2022)](https://aclanthology.org/2022.findings-acl.165/) for BBQ on ambiguous examples.",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "BBQ (ambiguous)",
        "run_group": "BBQ"
      }
    },
    {
      "value": "BBQ (unambiguous)",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\nBBQ (unambiguous): Metric of [Parrish et al. (2022)](https://aclanthology.org/2022.findings-acl.165/) for BBQ on unambiguous examples.",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "BBQ (unambiguous)",
        "run_group": "BBQ"
      }
    },
    {
      "value": "Denoised inference time (s)",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Denoised inference time (s)",
        "run_group": "BBQ"
      }
    },
    {
      "value": "# eval",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\n# eval: Number of evaluation instances.",
      "markdown": false,
      "metadata": {
        "metric": "# eval",
        "run_group": "BBQ"
      }
    },
    {
      "value": "# train",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\n# train: Number of training instances (e.g., in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "# train",
        "run_group": "BBQ"
      }
    },
    {
      "value": "truncated",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "truncated",
        "run_group": "BBQ"
      }
    },
    {
      "value": "# prompt tokens",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\n# prompt tokens: Number of tokens in the prompt.",
      "markdown": false,
      "metadata": {
        "metric": "# prompt tokens",
        "run_group": "BBQ"
      }
    },
    {
      "value": "# output tokens",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\n# output tokens: Actual number of output tokens.",
      "markdown": false,
      "metadata": {
        "metric": "# output tokens",
        "run_group": "BBQ"
      }
    },
    {
      "value": "# trials",
      "description": "The Bias Benchmark for Question Answering (BBQ) for measuring social bias in question answering in ambiguous and unambigous context [(Parrish et al., 2022)](https://aclanthology.org/2022.findings-acl.165/).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
      "markdown": false,
      "metadata": {
        "metric": "# trials",
        "run_group": "BBQ"
      }
    }
  ],
  "rows": [
    [
      {
        "value": "SantaCoder (1.1B)",
        "description": "",
        "markdown": false
      },
      {
        "value": 0.44999999999999996,
        "description": "min=0.3, mean=0.45, max=0.6, sum=0.9 (2)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false
      },
      {
        "value": 0.08333333333333334,
        "description": "min=-0.233, mean=0.083, max=0.4, sum=0.167 (2)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false
      },
      {
        "value": -1.0,
        "description": "min=-1, mean=-1, max=-1, sum=-2 (2)",
        "style": {
          "font-weight": "bold"
        },
        "markdown": false
      },
      {
        "description": "12 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "value": 10.0,
        "description": "min=10, mean=10, max=10, sum=20 (2)",
        "style": {},
        "markdown": false
      },
      {
        "value": 5.0,
        "description": "min=5, mean=5, max=5, sum=10 (2)",
        "style": {},
        "markdown": false
      },
      {
        "value": 0.0,
        "description": "min=0, mean=0, max=0, sum=0 (2)",
        "style": {},
        "markdown": false
      },
      {
        "value": 481.20000000000005,
        "description": "min=479.6, mean=481.2, max=482.8, sum=962.4 (2)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=2 (2)",
        "style": {},
        "markdown": false
      },
      {
        "value": 1.0,
        "description": "min=1, mean=1, max=1, sum=2 (2)",
        "style": {},
        "markdown": false
      }
    ]
  ],
  "links": [
    {
      "text": "LaTeX",
      "href": "benchmark_output/runs/paper/groups/latex/bbq_bbq.tex"
    },
    {
      "text": "JSON",
      "href": "benchmark_output/runs/paper/groups/json/bbq_bbq.json"
    }
  ],
  "name": "bbq"
}