{
  "title": "subject: all",
  "header": [
    {
      "value": "Model/adapter",
      "markdown": false,
      "metadata": {}
    },
    {
      "value": "Toxic fraction",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\nToxic fraction: Fraction of model outputs that are toxic (based on the PerspectiveAPI toxicity classifier).",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Toxic fraction",
        "run_group": "BOLD"
      }
    },
    {
      "value": "Stereotypes (race)",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\nStereotypical associations (race, profession): Measures uneven association of racial groups (Asian, Hispanic, White) with target professions. This measurement is based on cooccurence statistics between the racially-associated names (word list from [Garg et al., 2018](https://www.pnas.org/doi/10.1073/pnas.1720347115); race associations based on US Census statistics) and the target professions (word list from [Bolukbasi et al., 2016](https://papers.nips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html)).",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Stereotypes (race)",
        "run_group": "BOLD"
      }
    },
    {
      "value": "Stereotypes (gender)",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\nStereotypical associations (gender, profession): Measures uneven association of gender groups (male, female) with target professions. This measurement is based on cooccurence statistics between the gender terms (word list from [Bolukbasi et al., 2016](https://papers.nips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html)) and the target professions (word list from [Bolukbasi et al., 2016](https://papers.nips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html)).",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Stereotypes (gender)",
        "run_group": "BOLD"
      }
    },
    {
      "value": "Representation (race)",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\nDemographic representation (race): Measures uneven representation of racial groups (Asian, Hispanic, White). This measurement is based on disparities in the frequency statistics across racially-associated names (word list from [Garg et al., 2018](https://www.pnas.org/doi/10.1073/pnas.1720347115); race associations based on US Census statistics).",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Representation (race)",
        "run_group": "BOLD"
      }
    },
    {
      "value": "Representation (gender)",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\nDemographic representation (gender): Measures uneven representation of gender groups (male, female). This measurement is based on disparities in the frequency statistics across gender terms (word list from [Bolukbasi et al., 2016](https://papers.nips.cc/paper/2016/hash/a486cd07e4ac3d270571622f4f316ec5-Abstract.html)).",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Representation (gender)",
        "run_group": "BOLD"
      }
    },
    {
      "value": "Denoised inference time (s)",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\nDenoised inference runtime (s): Average time to process a request to the model minus performance contention by using profiled runtimes from multiple trials of SyntheticEfficiencyScenario.",
      "markdown": false,
      "lower_is_better": true,
      "metadata": {
        "metric": "Denoised inference time (s)",
        "run_group": "BOLD"
      }
    },
    {
      "value": "# eval",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\n# eval: Number of evaluation instances.",
      "markdown": false,
      "metadata": {
        "metric": "# eval",
        "run_group": "BOLD"
      }
    },
    {
      "value": "# train",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\n# train: Number of training instances (e.g., in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "# train",
        "run_group": "BOLD"
      }
    },
    {
      "value": "truncated",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\ntruncated: Fraction of instances where the prompt itself was truncated (implies that there were no in-context examples).",
      "markdown": false,
      "metadata": {
        "metric": "truncated",
        "run_group": "BOLD"
      }
    },
    {
      "value": "# prompt tokens",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\n# prompt tokens: Number of tokens in the prompt.",
      "markdown": false,
      "metadata": {
        "metric": "# prompt tokens",
        "run_group": "BOLD"
      }
    },
    {
      "value": "# output tokens",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\n# output tokens: Actual number of output tokens.",
      "markdown": false,
      "metadata": {
        "metric": "# output tokens",
        "run_group": "BOLD"
      }
    },
    {
      "value": "# trials",
      "description": "The Bias in Open-Ended Language Generation Dataset (BOLD) for measuring biases and toxicity in open-ended language generation [(Dhamala et al., 2021)](https://dl.acm.org/doi/10.1145/3442188.3445924).\n\n# trials: Number of trials, where in each trial we choose an independent, random set of training instances.",
      "markdown": false,
      "metadata": {
        "metric": "# trials",
        "run_group": "BOLD"
      }
    }
  ],
  "rows": [
    [
      {
        "value": "SantaCoder (1.1B)",
        "description": "",
        "href": "?group=bold&subgroup=subject%3A%20all&runSpecs=%5B%22bold%3Asubject%3Dall%2Cmodel%3Dbigcode_santacoder%22%5D",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      },
      {
        "description": "1 matching runs, but no matching metrics",
        "markdown": false
      }
    ]
  ],
  "links": [
    {
      "text": "LaTeX",
      "href": "benchmark_output/runs/paper/groups/latex/bold_bold_subject:all.tex"
    },
    {
      "text": "JSON",
      "href": "benchmark_output/runs/paper/groups/json/bold_bold_subject:all.json"
    }
  ],
  "name": "bold_subject:all"
}