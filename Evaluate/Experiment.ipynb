{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import torch \n",
    "from random import randint, seed\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer, pipeline\n",
    "import evaluate\n",
    "import matplotlib.pyplot as plt\n",
    "import gc \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_prompts(dataset, num_examples=100):\n",
    "    if num_examples >= len(dataset):\n",
    "        num_examples=len(dataset)\n",
    "    picks = []\n",
    "    pick_indice=[]\n",
    "    for _ in range(num_examples):\n",
    "        pick = randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = randint(0, len(dataset)-1)\n",
    "        pick_indice.append(pick)\n",
    "        picks.append(dataset[pick])\n",
    "    return picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kdai332/.conda/envs/evaluate-venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for MilaNLProc/honest contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/MilaNLProc/honest\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4326afd9917745ca9835e08d0ee841f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb81c7e20c69447e85e08af108804fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.56k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c1cbf0d31848d59f88d060b14e62c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/74.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a90e6517ac4712b777de134ed9b208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating honest split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default facebook/roberta-hate-speech-dynabench-r4-target checkpoint\n"
     ]
    }
   ],
   "source": [
    "toxicity_dataset=load_dataset(\"allenai/real-toxicity-prompts\", split=\"train\")\n",
    "regard_dataset=load_dataset(\"AlexaAI/bold\",split=\"train\")\n",
    "honest_dataset=load_dataset(\"MilaNLProc/honest\",\"en_queer_nonqueer\",split=\"honest\")\n",
    "\n",
    "regard=evaluate.load(\"regard\",\"compare\")\n",
    "toxicity = evaluate.load(\"toxicity\")\n",
    "honest=evaluate.load(\"honest\",\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_bold=[b[\"prompts\"][0] for b in regard_dataset if b[\"category\"]==\"American_actresses\"]\n",
    "male_bold=[b[\"prompts\"][0] for b in regard_dataset if b[\"category\"]==\"American_actors\"]\n",
    "honest_queer=[h[\"template_masked\"].replace(' [M].',\"\") for h in honest_dataset if h['category'].startswith('queer')]\n",
    "honest_nonqueer=[h[\"template_masked\"].replace(' [M].',\"\") for h in honest_dataset if h['category'].startswith('nonqueer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1000)\n",
    "\n",
    "test_sample= sample_prompts(toxicity_dataset,200)\n",
    "test_prompts = [p['prompt']['text'] for p in test_sample]\n",
    "\n",
    "seed(2000)\n",
    "\n",
    "female_sample=sample_prompts(female_bold,100)\n",
    "male_sample=sample_prompts(male_bold,100)\n",
    "\n",
    "seed(3000)\n",
    "\n",
    "queer_sample=sample_prompts(honest_queer,75)\n",
    "nonqueer_sample=sample_prompts(honest_nonqueer,75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixtral 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c1ca7d165c491288422fa8d97d7ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", torch_dtype=torch.float16, trust_remote_code=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mixtral-8x7B-Instruct-v0.1\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixtral_generate(prompts,honest):\n",
    "    outputs=[]\n",
    "    for p in tqdm(prompts,total=len(prompts),desc=\"Generating Texts\"):\n",
    "        inputs=tokenizer(p, return_tensors=\"pt\").to(\"cuda\")\n",
    "        if(honest):\n",
    "            output = model.generate(**inputs, max_length=len(tokenizer(p)['input_ids'])+10,num_return_sequences=20, pad_token_id=tokenizer.eos_token_id).to(\"cuda\")\n",
    "            generation=tokenizer.batch_decode(output[:3], skip_special_tokens=True)\n",
    "            generation=[g.replace(p,\"\") for g in generation]\n",
    "        else:\n",
    "            output = model.generate(**inputs, max_new_tokens=40, pad_token_id=tokenizer.eos_token_id).to(\"cuda\")\n",
    "            generation=tokenizer.decode(output[0], skip_special_tokens=True).replace(p,\"\")\n",
    "        outputs.append(generation)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixtral 7B Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15be7dc4131e4a6a9c81e35823cf69d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_continuations=mixtral_generate(test_prompts,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixtral_toxicty_rate=toxicity.compute(predictions=model_continuations, aggregation=\"ratio\")[\"toxicity_ratio\"]\n",
    "mixtral_toxicty=toxicity.compute(predictions=model_continuations)[\"toxicity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixtral 7B Regard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0a4cd28a944be1b81204ddd613efd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eab8c18626a4c53b4571b5b671d0b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "female_continuations=mixtral_generate(female_sample,False)\n",
    "male_continuations=mixtral_generate(male_sample,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mixtral_regard_diff=regard.compute(data=male_continuations,references=female_continuations)[\"regard_difference\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixtral 7B Honest\n",
    "\n",
    "Mixtral is not suitable to output \"num_return_sequences\" other than 1, making it unable to output several potential outputs for one single prompts. Since Honest expect a list of potential outputs for one single prompt, Mixtral is incompatible with Honest measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- configuration_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ceb1b92ac674144aafbc41b9f261aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi.py:   0%|          | 0.00/62.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- modeling_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0134920b852f47238d8d922af464025d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9a6bd25f2d438b8dbb8c7cd235611e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_generate(prompts,honest):\n",
    "    outputs=[]\n",
    "    for p in tqdm(prompts,total=len(prompts),desc=\"Generating Texts\"):\n",
    "        inputs=tokenizer(p, return_tensors=\"pt\", return_attention_mask=False).to(\"cuda\")\n",
    "        if(honest):\n",
    "            output = model.generate(**inputs, max_length=len(tokenizer(p)['input_ids'])+10,num_return_sequences=20, pad_token_id=tokenizer.eos_token_id).to(\"cuda\")\n",
    "            generation=generation[0]['generated_text'].replace(p,'')\n",
    "        else:\n",
    "            output = model.generate(**inputs, max_new_tokens=40, pad_token_id=tokenizer.eos_token_id).to(\"cuda\")\n",
    "            generation=tokenizer.decode(output[0]).replace(p,\"\")\n",
    "        outputs.append(generation)\n",
    "    return outputs\n",
    "    outputs=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi-2 Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ec25fadf744e16a9f79cd7f9fdc936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_continuations=phi_generate(test_prompts,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_toxicty_rate=toxicity.compute(predictions=model_continuations, aggregation=\"ratio\")[\"toxicity_ratio\"]\n",
    "phi_toxicty=toxicity.compute(predictions=model_continuations)[\"toxicity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi-2 Regard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f253d0e6d3974dff84ce4a2051131dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d540653da7394e96bdc349d273464db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "female_continuations=phi_generate(female_sample,False)\n",
    "male_continuations=phi_generate(male_sample,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_regard_diff=regard.compute(data=male_continuations,references=female_continuations)[\"regard_difference\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phi Honest\n",
    "\n",
    "Phi-2 is not suitable to output \"num_return_sequences\" other than 1, making it unable to output several potential outputs for one single prompts. Since Honest expect a list of potential outputs for one single prompt, Phi-2 is incompatible with Honest measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLaMa Pro 8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6105884497e7460585ca604c833d229a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"TencentARC/LLaMA-Pro-8B-Instruct\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TencentARC/LLaMA-Pro-8B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMa Pro Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d34345d8968541dcaa56ee8ff9898248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_continuations=mixtral_generate(test_prompts,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLaMa_toxicty_rate=toxicity.compute(predictions=model_continuations, aggregation=\"ratio\")[\"toxicity_ratio\"]\n",
    "LLaMa_toxicty=toxicity.compute(predictions=model_continuations)[\"toxicity\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMa Regard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7697125d188749a5b66b5c8d9ae79d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17d7f25f85247b693024a9750421029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "female_continuations=mixtral_generate(female_sample,False)\n",
    "male_continuations=mixtral_generate(male_sample,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLaMa_regard_diff=regard.compute(data=male_continuations,references=female_continuations)[\"regard_difference\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMa Honest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31b97d2715f545db962d8fe99be5c014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c879bf8c91d44d481d30d1fb9f2ec40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Texts:   0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "queer_continuations=mixtral_generate(queer_sample,True)\n",
    "nonquer_continuations=mixtral_generate(nonqueer_sample,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=[\"queer\"]*75+[\"nonqueer\"]*75\n",
    "continuations=[q for q in queer_continuations]+[nq for nq in nonquer_continuations]\n",
    "\n",
    "LLaMa_honest=honest.compute(predictions=continuations,groups=groups)[\"honest_score_per_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"LLaMa_toxicty_rate.txt\",\"a\") as fq:\n",
    "    fq.write(str(LLaMa_toxicty_rate))\n",
    "\n",
    "with open(\"LLaMa_toxicty.txt\",\"a\") as fq:\n",
    "    fq.write(str(LLaMa_toxicty))\n",
    "    \n",
    "with open(\"LLaMa_regard_diff.txt\",\"a\") as fq:\n",
    "    fq.write(str(LLaMa_regard_diff))\n",
    "    \n",
    "with open(\"LLaMa_toxicty_rate_honest.txt\",\"a\") as fq:\n",
    "    fq.write(str(LLaMa_toxicty_rate_honest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
