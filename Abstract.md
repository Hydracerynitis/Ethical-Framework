# Bias Evaluation Framework Survey (Expert Audience)

Studies have found evidence that machine learning models, despite being very accurate, can propagate bias present in the datasets through their predictions. To solve the bias problem, fairness machine learning becomes an emerging research field focusing on quantifying bias of models' predictions and designing methods to mitigate those biases without trading too much accuracy. Bias evaluation frameworks are one of the product of fairness machine learning. They offer tools to calculate fairness metrics of models, provide bias mitigation implementations, and sometimes automate benchmark experiments. My survey examines the current state of bias evaluation frameworks on tabular models and language models, and identifies any problems that their future mass adaption may encounter. For each framework, I learn to incorporate it into a mock up experiment, and evaluate its strengths and weaknesses based on my personal experience. My main finding is that common problems that all frameworks in the survey have are that their roster of fairness metrics are limited to evaluate the relative correctness of predictions across protected and privileged groups. In addition they also lack guidance for new users to understand the purpose and usage of different metrics.

# Fairness Evaluation Framework Survey (Educated, but Non-expert Audience)

AI technologies, such as tabular models and lanaguage models, have become more and more prevalent in the day-to-day decision making process in recent times all thanks to their accuracy and knowledgeableness. However, studies have found evidence that those models have risk of making discriminatory decisions due to bias present in its training data. To address this fairness problem, fairness machine learning emerge as a new research field in machine learning discipline. Fairness evaluation frameworks are one of the research field's product, providing tools to quantify bias a model may express with fairness metrics and sometimes offer methods to help reduce such bias. My survey examines the current state of bias evaluation frameworks both models, and identifies any problems that their future mass adaption may encounter. For each framework, I learn to incorporate it into a mock up experiment, and evaluate its strengths and weaknesses based on my personal experience. My main finding is that all frameworks in the survey offer a limited view of fairness, regarding it as the sameness of treatment (i.e. equality). As a result, they may not be capable to cover situation where propotional fairness (i.e. equity) are more relevant.